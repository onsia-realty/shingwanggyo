# ğŸš€ Universal Website Image Scraper Pro

> **ê°•ë ¥í•œ Playwright ê¸°ë°˜ ì›¹ì‚¬ì´íŠ¸ ì´ë¯¸ì§€ ìˆ˜ì§‘ ë„êµ¬**  
> ëª¨ë“  ì›¹ì‚¬ì´íŠ¸ì˜ ì´ë¯¸ì§€ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” í”„ë¡œí˜ì…”ë„ ìŠ¤í¬ë˜í¼

## âœ¨ í•µì‹¬ ê¸°ëŠ¥

- ğŸ–¼ï¸ **ì™„ë²½í•œ ì´ë¯¸ì§€ ê°ì§€**: img, picture, background-image, srcset, lazy loading ë“± ëª¨ë“  í˜•íƒœ
- ğŸ”„ **ë‹¤ì¤‘ í˜ì´ì§€ í¬ë¡¤ë§**: ì‚¬ì´íŠ¸ ì „ì²´ í˜ì´ì§€ ìë™ íƒìƒ‰
- ğŸ“ **ì²´ê³„ì ì¸ ì €ì¥**: í˜ì´ì§€ë³„ í´ë” ìë™ ë¶„ë¥˜
- ğŸ¤– **ìŠ¤ë§ˆíŠ¸ í¬ë¡¤ë§**: robots.txt ì¤€ìˆ˜, ì¤‘ë³µ ì œê±°, ì˜ˆì˜ìˆëŠ” ë”œë ˆì´
- ğŸ“Š **ìƒì„¸í•œ í†µê³„**: ì‹¤ì‹œê°„ ì§„í–‰ë¥ , ì„±ê³µ/ì‹¤íŒ¨ ë¦¬í¬íŠ¸
- ğŸ¯ **ë†’ì€ ì„±ê³µë¥ **: íƒ€ì„ì•„ì›ƒ, ë¦¬ë‹¤ì´ë ‰íŠ¸, 404 ì—ëŸ¬ ìë™ ì²˜ë¦¬

---

## ğŸ“¦ ì„¤ì¹˜ ë°©ë²•

### 1. í”„ë¡œì íŠ¸ ìƒì„±
```bash
# ìƒˆ í´ë” ìƒì„±
mkdir my-scraper
cd my-scraper

# package.json ìƒì„±
npm init -y
```

### 2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# Playwrightì™€ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
npm install playwright
npm install playwright-chromium

# Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜ (Chromium)
npx playwright install chromium
```

---

## ğŸ¯ ì‚¬ìš©ë²•

### ë°©ë²• 1: ê°„ë‹¨í•œ ë‹¨ì¼ í˜ì´ì§€ ìŠ¤í¬ë˜í¼

**`simple-scraper.js` íŒŒì¼ ìƒì„±:**

```javascript
const { chromium } = require('playwright');
const fs = require('fs').promises;
const path = require('path');

// âš™ï¸ ì„¤ì • - ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”!
const TARGET_URL = 'https://example.com';  // ğŸ¯ ìŠ¤í¬ë˜í•‘í•  ì‚¬ì´íŠ¸ URL
const OUTPUT_DIR = './downloaded-images';   // ğŸ“ ì €ì¥í•  í´ë”

async function scrapeImages() {
  console.log('ğŸš€ Starting image scraper...');
  
  const browser = await chromium.launch({ headless: true });
  const context = await browser.newContext({
    userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
  });
  
  const page = await context.newPage();
  
  try {
    console.log(`ğŸ“„ Navigating to: ${TARGET_URL}`);
    await page.goto(TARGET_URL, {
      waitUntil: 'networkidle',
      timeout: 60000
    });
    
    console.log('ğŸ” Extracting images...');
    
    const imageUrls = await page.evaluate(() => {
      const images = new Set();
      const baseUrl = window.location.origin;
      
      function resolveUrl(url) {
        if (!url) return null;
        try {
          return new URL(url, baseUrl).href;
        } catch {
          return null;
        }
      }
      
      // img íƒœê·¸
      document.querySelectorAll('img').forEach(img => {
        if (img.src) images.add(resolveUrl(img.src));
      });
      
      // ë°°ê²½ ì´ë¯¸ì§€
      document.querySelectorAll('*').forEach(el => {
        const style = window.getComputedStyle(el);
        const bg = style.backgroundImage;
        if (bg && bg !== 'none') {
          const matches = bg.match(/url\(["']?([^"')]+)["']?\)/);
          if (matches && matches[1]) {
            const resolved = resolveUrl(matches[1]);
            if (resolved && !resolved.startsWith('data:')) {
              images.add(resolved);
            }
          }
        }
      });
      
      return Array.from(images);
    });
    
    console.log(`âœ… Found ${imageUrls.length} images`);
    
    // í´ë” ìƒì„±
    await fs.mkdir(OUTPUT_DIR, { recursive: true });
    
    // ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    let downloaded = 0;
    for (const imageUrl of imageUrls) {
      try {
        console.log(`ğŸ“¥ Downloading: ${imageUrl}`);
        
        const response = await context.request.get(imageUrl, {
          timeout: 30000
        });
        
        if (response.ok()) {
          const buffer = await response.body();
          const filename = path.basename(new URL(imageUrl).pathname) || `image_${downloaded + 1}.jpg`;
          const filePath = path.join(OUTPUT_DIR, filename);
          
          await fs.writeFile(filePath, buffer);
          console.log(`âœ… Saved: ${filename}`);
          downloaded++;
        }
      } catch (error) {
        console.error(`âŒ Failed: ${error.message}`);
      }
    }
    
    console.log(`\nğŸ“Š Downloaded ${downloaded}/${imageUrls.length} images`);
    console.log(`ğŸ“ Saved to: ${path.resolve(OUTPUT_DIR)}`);
    
  } catch (error) {
    console.error('âŒ Error:', error);
  } finally {
    await browser.close();
  }
}

scrapeImages().catch(console.error);
```

**ì‹¤í–‰:**
```bash
node simple-scraper.js
```

---

### ë°©ë²• 2: ì „ì²´ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬ (ì—¬ëŸ¬ í˜ì´ì§€)

**`full-site-scraper.js` íŒŒì¼ ìƒì„±:**

```javascript
const { chromium } = require('playwright');
const fs = require('fs').promises;
const path = require('path');

// âš™ï¸ ì„¤ì • - ì›í•˜ëŠ” í˜ì´ì§€ë“¤ì„ ì¶”ê°€í•˜ì„¸ìš”!
const PAGES_TO_SCRAPE = [
  'https://example.com/',
  'https://example.com/about',
  'https://example.com/products',
  'https://example.com/contact',
  // ë” ë§ì€ í˜ì´ì§€ ì¶”ê°€...
];

const OUTPUT_DIR = './all-images';  // ğŸ“ ì €ì¥ í´ë”

async function scrapeAllPages() {
  console.log('ğŸš€ Starting site scraper...');
  console.log(`ğŸ“‹ Will scrape ${PAGES_TO_SCRAPE.length} pages\n`);
  
  const browser = await chromium.launch({ headless: true });
  const context = await browser.newContext({
    userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
  });
  
  const allImageUrls = new Set();
  
  try {
    // ê° í˜ì´ì§€ í¬ë¡¤ë§
    for (const pageUrl of PAGES_TO_SCRAPE) {
      console.log(`ğŸ“„ Processing: ${pageUrl}`);
      const page = await context.newPage();
      
      try {
        await page.waitForTimeout(Math.random() * 1000 + 500); // ì˜ˆì˜ìˆëŠ” ë”œë ˆì´
        await page.goto(pageUrl, {
          waitUntil: 'networkidle',
          timeout: 60000
        });
        
        // ìŠ¤í¬ë¡¤ (lazy loading ëŒ€ì‘)
        await autoScroll(page);
        
        const imageUrls = await page.evaluate(() => {
          const images = new Set();
          // ... ì´ë¯¸ì§€ ì¶”ì¶œ ë¡œì§ (ìœ„ì™€ ë™ì¼)
          document.querySelectorAll('img').forEach(img => {
            if (img.src) images.add(img.src);
          });
          return Array.from(images);
        });
        
        console.log(`  âœ… Found ${imageUrls.length} images`);
        imageUrls.forEach(url => allImageUrls.add(url));
        
      } catch (error) {
        console.error(`  âŒ Failed: ${error.message}`);
      } finally {
        await page.close();
      }
    }
    
    console.log(`\nğŸ“Š Total unique images: ${allImageUrls.size}`);
    
    // ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    await fs.mkdir(OUTPUT_DIR, { recursive: true });
    let downloaded = 0;
    
    for (const imageUrl of allImageUrls) {
      try {
        const response = await context.request.get(imageUrl);
        if (response.ok()) {
          const buffer = await response.body();
          const filename = path.basename(new URL(imageUrl).pathname) || `image_${downloaded + 1}.jpg`;
          await fs.writeFile(path.join(OUTPUT_DIR, filename), buffer);
          downloaded++;
        }
      } catch (error) {
        console.error(`âŒ Failed: ${error.message}`);
      }
    }
    
    console.log(`âœ… Downloaded ${downloaded} images to ${OUTPUT_DIR}`);
    
  } finally {
    await browser.close();
  }
}

// ìë™ ìŠ¤í¬ë¡¤ í•¨ìˆ˜
async function autoScroll(page) {
  await page.evaluate(async () => {
    await new Promise((resolve) => {
      let totalHeight = 0;
      const timer = setInterval(() => {
        window.scrollBy(0, 100);
        totalHeight += 100;
        if (totalHeight >= document.body.scrollHeight) {
          clearInterval(timer);
          resolve();
        }
      }, 100);
    });
  });
}

scrapeAllPages().catch(console.error);
```

---

## ğŸ® ì‚¬ìš© ì˜ˆì œ

### ì˜ˆì œ 1: ì‡¼í•‘ëª° ì´ë¯¸ì§€ ìˆ˜ì§‘
```javascript
const PAGES_TO_SCRAPE = [
  'https://shopping-site.com/',
  'https://shopping-site.com/products',
  'https://shopping-site.com/sale',
];
```

### ì˜ˆì œ 2: ê°¤ëŸ¬ë¦¬ ì‚¬ì´íŠ¸
```javascript
const TARGET_URL = 'https://gallery-site.com/photos';
```

### ì˜ˆì œ 3: ë‰´ìŠ¤ ì‚¬ì´íŠ¸
```javascript
const PAGES_TO_SCRAPE = [
  'https://news-site.com/',
  'https://news-site.com/today',
  'https://news-site.com/sports',
];
```

---

## ğŸ› ï¸ ê³ ê¸‰ ì„¤ì •

### íŠ¹ì • ì´ë¯¸ì§€ë§Œ í•„í„°ë§
```javascript
// í° ì´ë¯¸ì§€ë§Œ ë‹¤ìš´ë¡œë“œ (ì˜ˆ: 500px ì´ìƒ)
const imageUrls = await page.evaluate(() => {
  const images = [];
  document.querySelectorAll('img').forEach(img => {
    if (img.naturalWidth > 500 && img.naturalHeight > 500) {
      images.push(img.src);
    }
  });
  return images;
});
```

### íŠ¹ì • í™•ì¥ìë§Œ ë‹¤ìš´ë¡œë“œ
```javascript
const validExtensions = ['.jpg', '.jpeg', '.png', '.webp'];
const filteredUrls = imageUrls.filter(url => 
  validExtensions.some(ext => url.toLowerCase().includes(ext))
);
```

### íŒŒì¼ëª… ì»¤ìŠ¤í„°ë§ˆì´ì§•
```javascript
// ë‚ ì§œì™€ ìˆœë²ˆìœ¼ë¡œ ì €ì¥
const date = new Date().toISOString().split('T')[0];
const filename = `${date}_image_${downloaded + 1}.jpg`;
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ (ë” ë¹ ë¥´ê²Œ!)
```javascript
// Promise.allë¡œ ë™ì‹œ ë‹¤ìš´ë¡œë“œ
const downloadPromises = imageUrls.map(async (url, index) => {
  try {
    const response = await context.request.get(url);
    if (response.ok()) {
      const buffer = await response.body();
      const filename = `image_${index}.jpg`;
      await fs.writeFile(path.join(OUTPUT_DIR, filename), buffer);
      return true;
    }
  } catch (error) {
    console.error(`Failed: ${url}`);
    return false;
  }
});

const results = await Promise.all(downloadPromises);
const successCount = results.filter(r => r).length;
```

---

## ğŸš¨ ë¬¸ì œ í•´ê²°

### 1. "Timeout exceeded" ì—ëŸ¬
```javascript
// íƒ€ì„ì•„ì›ƒ ëŠ˜ë¦¬ê¸°
await page.goto(url, {
  timeout: 120000  // 2ë¶„
});
```

### 2. ë¡œê·¸ì¸ì´ í•„ìš”í•œ ì‚¬ì´íŠ¸
```javascript
// ë¡œê·¸ì¸ ì²˜ë¦¬
await page.fill('#username', 'your-username');
await page.fill('#password', 'your-password');
await page.click('#login-button');
await page.waitForNavigation();
```

### 3. ë¬´í•œ ìŠ¤í¬ë¡¤ ì‚¬ì´íŠ¸
```javascript
// ë¬´í•œ ìŠ¤í¬ë¡¤ ëŒ€ì‘
for (let i = 0; i < 10; i++) {
  await page.evaluate(() => window.scrollTo(0, document.body.scrollHeight));
  await page.waitForTimeout(2000);
}
```

---

## ğŸ’¡ í”„ë¡œ íŒ

1. **User-Agent ë³€ê²½**: ì°¨ë‹¨ ë°©ì§€
```javascript
userAgent: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'
```

2. **í”„ë¡ì‹œ ì‚¬ìš©**: IP ì°¨ë‹¨ ìš°íšŒ
```javascript
const browser = await chromium.launch({
  proxy: { server: 'http://proxy.example.com:8080' }
});
```

3. **ì¿ í‚¤ ì €ì¥/ë¡œë“œ**: ì„¸ì…˜ ìœ ì§€
```javascript
// ì¿ í‚¤ ì €ì¥
const cookies = await context.cookies();
await fs.writeFile('cookies.json', JSON.stringify(cookies));

// ì¿ í‚¤ ë¡œë“œ
const cookies = JSON.parse(await fs.readFile('cookies.json'));
await context.addCookies(cookies);
```

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

MIT License - ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ì„¸ìš”!

---

## ğŸ¤ ê¸°ì—¬

ì´ ë„êµ¬ê°€ ìœ ìš©í•˜ì…¨ë‹¤ë©´ â­ ìŠ¤íƒ€ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!

---

**Made with â¤ï¸ by Senior Crawling Engineer**